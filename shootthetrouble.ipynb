{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_LOAD MODEL DONE_\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import pickle\n",
    "sys.path.insert(1, '/home/mhbrt/Desktop/Wind/Multiscale/')\n",
    "import complete_flow as flow\n",
    "# model = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "[{'tanwin_1': 0.8251692056655884, 'box_tanwin_1': array([[ 49, 309,  64, 317],\n",
      "       [171, 301, 185, 308],\n",
      "       [ 30, 191,  45, 200],\n",
      "       [170, 177, 185, 185],\n",
      "       [126,  30, 141,  39],\n",
      "       [ 92,  11, 105,  19]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg_1': 0, 'box_nun_beg_1': 0, 'nun_beg_2': 0, 'box_nun_beg_2': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0.7675055861473083, 'box_mim_beg': array([[126, 266, 141, 294],\n",
      "       [148, 149, 163, 177],\n",
      "       [331, 151, 344, 176],\n",
      "       [191,  38, 204,  62]]), 'mim_mid': 0.736183226108551, 'box_mim_mid': array([[266, 270, 281, 299],\n",
      "       [ 91, 155, 105, 180],\n",
      "       [280, 155, 293, 180],\n",
      "       [ 51, 159,  62, 179],\n",
      "       [193,  35, 208,  64],\n",
      "       [307,  42, 318,  62]]), 'mim_end_1': 0.7912454009056091, 'box_mim_end_1': array([[186, 270, 201, 316],\n",
      "       [264, 269, 278, 315],\n",
      "       [278, 154, 290, 194],\n",
      "       [192,  39, 203,  75]]), 'mim_end_2': 0, 'box_mim_end_2': 0}, {'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0.70151686668396, 'box_mim_beg': array([[127, 269, 140, 293],\n",
      "       [149, 152, 161, 176],\n",
      "       [331, 152, 344, 176]]), 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg_1': 0, 'box_nun_beg_1': 0, 'nun_beg_2': 0, 'box_nun_beg_2': 0, 'nun_mid': 0.7100228667259216, 'box_nun_mid': array([[ 58,  36,  68,  60],\n",
      "       [229,  36, 240,  60]]), 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0.7524977326393127, 'box_mim_beg': array([[125, 267, 141, 295],\n",
      "       [328, 150, 345, 178],\n",
      "       [147, 152, 162, 177]]), 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end_1': 0, 'box_mim_end_1': 0, 'mim_end_2': 0, 'box_mim_end_2': 0}, {'tanwin_1': 0.7096700668334961, 'box_tanwin_1': array([[174, 300, 185, 310],\n",
      "       [126,  31, 137,  41]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0.8104432225227356, 'box_tanwin_1': array([[ 47, 307,  65, 322],\n",
      "       [170, 298, 188, 313],\n",
      "       [ 28, 189,  46, 204],\n",
      "       [168, 176, 183, 189],\n",
      "       [126,  29, 141,  41]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0.7835696339607239, 'box_tanwin_1': array([[ 50, 310,  59, 320],\n",
      "       [173, 300, 184, 311],\n",
      "       [ 30, 191,  41, 203],\n",
      "       [257, 181, 268, 193],\n",
      "       [170, 178, 180, 189],\n",
      "       [129,  30, 140,  41]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0.7660278081893921, 'box_mim_mid': array([[125, 268, 141, 295],\n",
      "       [328, 151, 345, 178],\n",
      "       [147, 154, 162, 177]]), 'mim_end': 0.7040371894836426, 'box_mim_end': array([[227,  35, 242,  61],\n",
      "       [ 55,  35,  71,  61]])}, {'tanwin_1': 0.724206805229187, 'box_tanwin_1': array([[170, 299, 185, 312],\n",
      "       [126,  29, 141,  42]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0.7133476734161377, 'box_nun_mid': array([[ 44, 149,  60, 178],\n",
      "       [ 53,  32,  69,  61]]), 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0.7698626518249512, 'box_tanwin_1': array([[ 49, 308,  66, 321],\n",
      "       [170, 300, 187, 313],\n",
      "       [ 86, 243, 103, 256],\n",
      "       [ 29, 191,  46, 204],\n",
      "       [128,  30, 142,  40]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0.7383620142936707, 'box_mim_beg': array([[125, 266, 142, 296],\n",
      "       [329, 148, 346, 178],\n",
      "       [148, 151, 163, 177]]), 'mim_mid': 0.7174369096755981, 'box_mim_mid': array([[266, 268, 279, 296],\n",
      "       [188, 271, 199, 296],\n",
      "       [ 49, 151,  62, 180],\n",
      "       [315, 150, 328, 179],\n",
      "       [279, 150, 292, 179],\n",
      "       [ 94, 154, 105, 179],\n",
      "       [230,  34, 243,  62],\n",
      "       [ 58,  34,  71,  62]]), 'mim_end': 0, 'box_mim_end': 0}]\n",
      "tanwin_1\n",
      "start point from mess: [309, 318]\n",
      "[50, 300, 63, 309]\n",
      "[50, 318, 63, 324]\n",
      "upper\n",
      "159\n",
      "start point from mess: [264, 304]\n",
      "al_height: 40\n",
      "start point from mess: [253, 319]\n",
      "[[253, 319]]\n",
      "start point from mess: [301, 310]\n",
      "[173, 292, 184, 301]\n",
      "[173, 310, 184, 319]\n",
      "enlarge\n",
      "387\n",
      "start point from mess: [278, 294]\n",
      "al_height: 16\n",
      "start point from mess: [262, 311]\n",
      "[[253, 319], [262, 311]]\n",
      "start point from mess: [192, 201]\n",
      "[31, 183, 43, 192]\n",
      "[31, 201, 43, 210]\n",
      "upper\n",
      "397\n",
      "start point from mess: [146, 187]\n",
      "al_height: 41\n",
      "start point from mess: [122, 202]\n",
      "[[253, 319], [262, 311], [122, 202]]\n",
      "start point from mess: [177, 187]\n",
      "[171, 167, 183, 177]\n",
      "[171, 187, 183, 197]\n",
      "upper\n",
      "207\n",
      "start point from mess: [164, 190]\n",
      "al_height: 26\n",
      "start point from mess: [156, 191]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191]]\n",
      "start point from mess: [30, 39]\n",
      "[129, 21, 140, 30]\n",
      "[129, 39, 140, 48]\n",
      "lower\n",
      "59\n",
      "start point from mess: [27, 58]\n",
      "al_height: 31\n",
      "start point from mess: [25, 67]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67]]\n",
      "start point from mess: [11, 20]\n",
      "[93, 2, 105, 11]\n",
      "[93, 20, 105, 29]\n",
      "lower\n",
      "103\n",
      "start point from mess: [27, 58]\n",
      "al_height: 31\n",
      "start point from mess: [10, 67]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67]]\n",
      "mim_beg\n",
      "start point from mess: [262, 293]\n",
      "replace coordinat\n",
      "leftcount: 101\n",
      "start point from mess: [253, 306]\n",
      "al_height: 53\n",
      "start point from mess: [241, 307]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307]]\n",
      "start point from mess: [151, 190]\n",
      "leftcount: 80\n",
      "start point from mess: [152, 190]\n",
      "al_height: 38\n",
      "start point from mess: [148, 191]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191]]\n",
      "start point from mess: [162, 184]\n",
      "leftcount: 68\n",
      "start point from mess: [150, 184]\n",
      "al_height: 34\n",
      "start point from mess: [149, 185]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185]]\n",
      "start point from mess: [37, 81]\n",
      "leftcount: 29\n",
      "start point from mess: [25, 58]\n",
      "al_height: 33\n",
      "start point from mess: [24, 81]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81]]\n",
      "mim_mid\n",
      "start point from mess: [272, 315]\n",
      "leftcount: 12\n",
      "start point from mess: [274, 315]\n",
      "al_height: 41\n",
      "start point from mess: [252, 316]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316]]\n",
      "start point from mess: [163, 176]\n",
      "leftcount: 95\n",
      "start point from mess: [160, 184]\n",
      "al_height: 24\n",
      "start point from mess: [144, 197]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316], [144, 197]]\n",
      "start point from mess: [154, 198]\n",
      "leftcount: 9\n",
      "start point from mess: [154, 198]\n",
      "al_height: 44\n",
      "start point from mess: [153, 201]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316], [144, 197], [153, 201]]\n",
      "start point from mess: [146, 187]\n",
      "leftcount: 62\n",
      "start point from mess: [146, 187]\n",
      "al_height: 41\n",
      "start point from mess: [144, 197]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316], [144, 197], [153, 201], [144, 197]]\n",
      "start point from mess: [37, 81]\n",
      "leftcount: 31\n",
      "start point from mess: [25, 58]\n",
      "al_height: 33\n",
      "start point from mess: [24, 81]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316], [144, 197], [153, 201], [144, 197], [24, 81]]\n",
      "start point from mess: [30, 69]\n",
      "leftcount: 73\n",
      "start point from mess: [30, 69]\n",
      "al_height: 39\n",
      "start point from mess: [18, 70]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316], [144, 197], [153, 201], [144, 197], [24, 81], [18, 70]]\n",
      "mim_end_1\n",
      "start point from mess: [266, 309]\n",
      "leftcount: 158\n",
      "start point from mess: [270, 314]\n",
      "al_height: 44\n",
      "start point from mess: [266, 317]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316], [144, 197], [153, 201], [144, 197], [24, 81], [18, 70], [266, 317]]\n",
      "start point from mess: [268, 315]\n",
      "leftcount: 16\n",
      "start point from mess: [253, 293]\n",
      "al_height: 40\n",
      "start point from mess: [252, 316]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316], [144, 197], [153, 201], [144, 197], [24, 81], [18, 70], [266, 317], [252, 316]]\n",
      "start point from mess: [154, 198]\n",
      "leftcount: 7\n",
      "start point from mess: [182, 191]\n",
      "al_height: 9\n",
      "start point from mess: [153, 198]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316], [144, 197], [153, 201], [144, 197], [24, 81], [18, 70], [266, 317], [252, 316], [153, 198]]\n",
      "start point from mess: [37, 81]\n",
      "leftcount: 9\n",
      "start point from mess: [25, 58]\n",
      "al_height: 33\n",
      "start point from mess: [24, 81]\n",
      "[[253, 319], [262, 311], [122, 202], [156, 191], [25, 67], [10, 67], [241, 307], [148, 191], [149, 185], [24, 81], [252, 316], [144, 197], [153, 201], [144, 197], [24, 81], [18, 70], [266, 317], [252, 316], [153, 198], [24, 81]]\n",
      "[47, 112, 115, 141, 151, 261, 265, 372]\n",
      "[47, 102, 117, 141, 151, 251, 265, 372]\n",
      "[17, 114, 124, 162, 171, 200, 203, 267, 279, 372]\n",
      "[24, 114, 124, 162, 171, 200, 204, 267, 279, 372]\n",
      "[45, 78, 81, 97, 129, 183, 193, 271, 292, 328, 359, 371]\n",
      "[41, 78, 81, 104, 129, 183, 193, 271, 289, 328, 335, 354, 359, 371]\n",
      "[47, 112, 115, 141, 151, 261, 265, 372]\n",
      "[24, 114, 124, 162, 171, 200, 203, 267, 279, 372]\n",
      "[24, 114, 140, 162, 188, 200, 203, 265, 279, 344, 351, 372]\n",
      "[33, 97, 129, 183, 193, 271, 281, 345, 349, 371]\n",
      "[47, 112, 115, 141, 151, 261, 265, 372]\n",
      "[24, 114, 124, 162, 171, 200, 203, 267, 279, 372]\n",
      "[24, 114, 124, 162, 171, 200, 203, 267, 279, 372]\n",
      "[24, 114, 124, 162, 171, 200, 203, 267, 279, 372]\n",
      "[33, 97, 129, 183, 193, 271, 281, 345, 349, 371]\n",
      "[32, 78, 81, 103, 129, 183, 193, 271, 281, 348, 349, 371]\n",
      "[47, 102, 117, 141, 151, 251, 265, 372]\n",
      "[47, 112, 115, 141, 151, 261, 265, 372]\n",
      "[24, 114, 124, 162, 171, 200, 203, 267, 279, 372]\n",
      "[33, 97, 129, 183, 193, 271, 281, 345, 349, 371]\n",
      "True\n",
      "into eight connectivity\n",
      "processing: tanwin_1\n",
      "add beside next wall\n",
      "processing: tanwin_1\n",
      "add next wall\n",
      "processing: mim_beg\n",
      "add next wall\n",
      "processing: mim_mid\n",
      "add next wall\n",
      "processing: mim_mid\n",
      "add inside wall\n",
      "processing: mim_end_1\n",
      "add next wall\n",
      "CROP WORDS =  {'final_beside_tanwin_1_4': (99, 103), 'ordinat_tanwin_1_4': array([126,  30, 141,  39]), 'final_beside_tanwin_1_5': (281, 345), 'ordinat_tanwin_1_5': array([ 92,  11, 105,  19]), 'final_beside_mim_beg_3': (124, 183), 'ordinat_mim_beg_3': array([191,  38, 204,  62]), 'final_beside_mim_mid_4': (124, 183), 'ordinat_mim_mid_4': array([193,  35, 208,  64]), 'final_inside_mim_mid_5': (281, 345), 'ordinat_mim_mid_5': array([307,  42, 318,  62]), 'final_beside_mim_end_1_3': (124, 183), 'ordinat_mim_end_1_3': array([192,  39, 203,  75])}\n",
      "join = tanwin_1_4\n",
      "__Final word only have one marker__\n",
      "join = tanwin_1_5\n",
      "join = mim_beg_3\n",
      "join = mim_mid_4\n",
      "join = mim_mid_5\n",
      "__Final word only have one marker__\n",
      "join = mim_end_1_3\n",
      "into eight connectivity\n",
      "CROP WORDS =  {}\n",
      "into eight connectivity\n",
      "processing: tanwin_1\n",
      "processing: tanwin_1\n",
      "add next wall\n",
      "processing: mim_beg\n",
      "add next wall\n",
      "processing: mim_beg\n",
      "add inside wall\n",
      "processing: mim_mid\n",
      "add inside wall\n",
      "processing: mim_mid\n",
      "add next wall\n",
      "processing: mim_mid\n",
      "add inside wall\n",
      "processing: mim_end_1\n",
      "add next wall\n",
      "CROP WORDS =  {'final_beside_tanwin_1_3': (124, 162), 'ordinat_tanwin_1_3': array([170, 177, 185, 185]), 'final_beside_mim_beg_1': (24, 114), 'ordinat_mim_beg_1': array([148, 149, 163, 177]), 'final_inside_mim_beg_2': (279, 371), 'ordinat_mim_beg_2': array([331, 151, 344, 176]), 'final_inside_mim_mid_1': (24, 114), 'ordinat_mim_mid_1': array([ 91, 155, 105, 180]), 'final_beside_mim_mid_2': (203, 265), 'ordinat_mim_mid_2': array([280, 155, 293, 180]), 'final_inside_mim_mid_3': (24, 114), 'ordinat_mim_mid_3': array([ 51, 159,  62, 179]), 'final_beside_mim_end_1_2': (203, 265), 'ordinat_mim_end_1_2': array([278, 154, 290, 194])}\n",
      "join = tanwin_1_3\n",
      "join = mim_beg_1\n",
      "join = mim_beg_2\n",
      "join = mim_mid_1\n",
      "join = mim_mid_2\n",
      "join = mim_mid_3\n",
      "__Final word only have one marker__\n",
      "join = mim_end_1_2\n",
      "into eight connectivity\n",
      "processing: tanwin_1\n",
      "processing: tanwin_1\n",
      "add next wall\n",
      "processing: mim_beg\n",
      "add next wall\n",
      "processing: mim_mid\n",
      "add next wall\n",
      "processing: mim_end_1\n",
      "add next wall\n",
      "processing: mim_end_1\n",
      "add next wall\n",
      "CROP WORDS =  {'final_beside_tanwin_1_1': (116, 141), 'ordinat_tanwin_1_1': array([171, 301, 185, 308]), 'final_beside_mim_beg_0': (47, 113), 'ordinat_mim_beg_0': array([126, 266, 141, 294]), 'final_beside_mim_mid_0': (151, 262), 'ordinat_mim_mid_0': array([266, 270, 281, 299]), 'final_beside_mim_end_1_0': (116, 141), 'ordinat_mim_end_1_0': array([186, 270, 201, 316]), 'final_beside_mim_end_1_1': (151, 262), 'ordinat_mim_end_1_1': array([264, 269, 278, 315])}\n",
      "join = tanwin_1_1\n",
      "join = mim_beg_0\n",
      "join = mim_mid_0\n",
      "join = mim_end_1_0\n",
      "join = mim_end_1_1\n"
     ]
    }
   ],
   "source": [
    "imagePath = '/home/mhbrt/Desktop/Wind/Multiscale/temp/clear this!/3.png'\n",
    "markerPath = '/home/mhbrt/Desktop/Wind/Multiscale/marker'\n",
    "img = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "res = {'AlKareem': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'AlQalam': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'amiri': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'KFGQPC': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'LPMQ': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'norehidayat': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'norehira': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'norehuda': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'PDMS': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'meQuran': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10']}\n",
    "# font_list = mess.font(imagePath=imagePath, image=gray, setting=res)\n",
    "font_list, loc_path = flow.font_list(\n",
    "    imagePath=imagePath, image=gray, setting=res, markerPath=markerPath)\n",
    "temp_object = []\n",
    "imagelist_template_matching_result = []\n",
    "imagelist_template_scale_visualize = []\n",
    "imagelist_visualize_white_block = []\n",
    "for font_object in font_list:\n",
    "    font_object.run()\n",
    "    imagelist_template_scale_visualize.append(font_object.imagelist_visualize)\n",
    "    imagelist_visualize_white_block.append(font_object.imagelist_visualize_white_blok)\n",
    "    temp_object.append(font_object.get_object_result())\n",
    "    imagelist_template_matching_result.append(font_object.display_marker_result(img))\n",
    "#     yield font_folder[local_count]\n",
    "print(temp_object)\n",
    "# yield 'Doing BIG BLOK'\n",
    "max_id = flow.most_marker(temp_object)\n",
    "if max_id is None:\n",
    "#     yield 'empty'\n",
    "    print('empty')\n",
    "else:\n",
    "#     yield 'Image Processing'\n",
    "    save_state, normal_processing_result, crop_ratio_processing_result,\\\n",
    "    imagelist_horizontal_line_by_eight_conn = flow.define_normal_or_crop_processing(\n",
    "        imagePath, temp_object, max_id, font_object, font_list\n",
    "    )\n",
    "#     yield 'Recognition'\n",
    "\n",
    "#     yield 'DONE!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model type 1\n",
    "model_name = '/home/mhbrt/Desktop/Wind/Multiscale/Colab/best_model_DenseNet_DD.pkl'\n",
    "model = pickle.load(open(model_name, 'rb'))\n",
    "print('_LOAD MODEL DONE_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 56]\n",
      "[46, 63]\n",
      "[22, 56]\n",
      "[22, 56]\n",
      "[27, 67]\n",
      "[22, 56]\n",
      "[20, 32]\n",
      "[22, 32]\n",
      "[25, 42]\n",
      "[19, 41]\n",
      "[7, 36]\n",
      "[2, 58]\n",
      "[7, 36]\n",
      "[37, 50]\n",
      "[9, 50]\n",
      "[9, 50]\n",
      "[37, 50]\n",
      "[9, 50]\n",
      "idzhar halqi\n",
      "idzhar halqi\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idgham bigunnah\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "ikfha syafawi\n",
      "idzhar syafawi\n",
      "ikfha syafawi\n",
      "idgham bigunnah\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idgham mimi\n",
      "idzhar syafawi\n"
     ]
    }
   ],
   "source": [
    "final_image_result = flow.character_recognition(\n",
    "    save_state, imagePath, model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model type 2\n",
    "from keras.models import model_from_json\n",
    "json_file = open('/home/mhbrt/Desktop/Wind/Multiscale/Colab/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"/home/mhbrt/Desktop/Wind/Multiscale/Colab/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model type 3\n",
    "from keras.models import load_model\n",
    "keras_model = load_model('/home/mhbrt/Desktop/Wind/Multiscale/Colab/keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 56]\n",
      "[46, 63]\n",
      "[22, 56]\n",
      "[22, 56]\n",
      "[27, 67]\n",
      "[22, 56]\n",
      "[20, 32]\n",
      "[22, 32]\n",
      "[25, 42]\n",
      "[19, 41]\n",
      "[7, 36]\n",
      "[2, 58]\n",
      "[7, 36]\n",
      "[37, 50]\n",
      "[9, 50]\n",
      "[9, 50]\n",
      "[37, 50]\n",
      "[9, 50]\n",
      "idzhar halqi\n",
      "idzhar halqi\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idgham bigunnah\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "ikfha syafawi\n",
      "idzhar syafawi\n",
      "ikfha syafawi\n",
      "idgham bigunnah\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idgham mimi\n",
      "idzhar syafawi\n"
     ]
    }
   ],
   "source": [
    "final_image_result = flow.character_recognition(\n",
    "    save_state, imagePath, keras_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "run() Marker Font\n",
      "numstep =  10\n",
      "[{'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg_1': 0, 'box_nun_beg_1': 0, 'nun_beg_2': 0, 'box_nun_beg_2': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0.7021585702896118, 'box_mim_mid': array([[227, 723, 239, 746],\n",
      "       [358, 245, 371, 267]]), 'mim_end_1': 0, 'box_mim_end_1': 0, 'mim_end_2': 0, 'box_mim_end_2': 0}, {'tanwin_1': 0.7181983590126038, 'box_tanwin_1': array([[393, 505, 411, 523],\n",
      "       [319, 278, 337, 296]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0.7029514908790588, 'box_nun_stand': array([[240, 397, 265, 434],\n",
      "       [201, 240, 227, 277]]), 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0.7001128792762756, 'box_mim_beg': array([[281, 325, 296, 352],\n",
      "       [259, 155, 273, 182]]), 'mim_mid': 0.7088226675987244, 'box_mim_mid': array([[107, 340, 119, 362],\n",
      "       [ 37, 302,  49, 323]]), 'mim_end': 0.7006936073303223, 'box_mim_end': array([[159, 592, 177, 617],\n",
      "       [267, 245, 286, 269]])}, {'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg_1': 0, 'box_nun_beg_1': 0, 'nun_beg_2': 0, 'box_nun_beg_2': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end_1': 0, 'box_mim_end_1': 0, 'mim_end_2': 0, 'box_mim_end_2': 0}, {'tanwin_1': 0.7047240734100342, 'box_tanwin_1': array([[229, 475, 246, 491],\n",
      "       [318, 279, 335, 295]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0.7180666923522949, 'box_mim_beg': array([[163, 592, 176, 616],\n",
      "       [462, 317, 475, 340]]), 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0, 'box_tanwin_1': 0, 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0.7292138934135437, 'box_tanwin_1': array([[ 97, 629, 110, 640],\n",
      "       [250, 592, 260, 601],\n",
      "       [206, 498, 216, 507],\n",
      "       [362, 357, 375, 368]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0.7068450450897217, 'box_nun_beg': array([[324, 155, 337, 189],\n",
      "       [320, 110, 333, 144]]), 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0.7279755473136902, 'box_nun_end': array([[241, 400, 265, 434],\n",
      "       [315, 110, 339, 144]]), 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0.7131833434104919, 'box_mim_beg': array([[173, 318, 182, 341],\n",
      "       [473,  66, 482,  89]]), 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}, {'tanwin_1': 0.7306076288223267, 'box_tanwin_1': array([[133, 664, 144, 672],\n",
      "       [192, 659, 204, 668],\n",
      "       [ 68, 555,  79, 563],\n",
      "       [416, 513, 427, 521],\n",
      "       [350, 362, 362, 371],\n",
      "       [429, 178, 440, 186]]), 'tanwin_2': 0, 'box_tanwin_2': 0, 'nun_stand': 0, 'box_nun_stand': 0, 'nun_beg': 0, 'box_nun_beg': 0, 'nun_mid': 0, 'box_nun_mid': 0, 'nun_end': 0, 'box_nun_end': 0, 'mim_stand': 0, 'box_mim_stand': 0, 'mim_beg': 0, 'box_mim_beg': 0, 'mim_mid': 0, 'box_mim_mid': 0, 'mim_end': 0, 'box_mim_end': 0}]\n",
      "tanwin_1\n",
      "start point from mess: [506, 538]\n",
      "[393, 487, 411, 505]\n",
      "[393, 523, 411, 541]\n",
      "upper\n",
      "319\n",
      "start point from mess: [477, 504]\n",
      "al_height: 27\n",
      "start point from mess: [437, 538]\n",
      "[[437, 538]]\n",
      "start point from mess: [280, 314]\n",
      "[319, 260, 337, 278]\n",
      "[319, 296, 337, 314]\n",
      "upper\n",
      "123\n",
      "384\n",
      "start point from mess: [237, 281]\n",
      "al_height: 44\n",
      "start point from mess: [226, 314]\n",
      "[[437, 538], [226, 314]]\n",
      "nun_stand\n",
      "start point from mess: [376, 432]\n",
      "leftcount: 326\n",
      "start point from mess: [376, 440]\n",
      "al_height: 64\n",
      "start point from mess: [350, 475]\n",
      "[[437, 538], [226, 314], [350, 475]]\n",
      "start point from mess: [245, 277]\n",
      "leftcount: 324\n",
      "start point from mess: [213, 278]\n",
      "al_height: 65\n",
      "start point from mess: [179, 310]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310]]\n",
      "mim_beg\n",
      "start point from mess: [321, 352]\n",
      "leftcount: 129\n",
      "start point from mess: [324, 352]\n",
      "al_height: 28\n",
      "start point from mess: [313, 379]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379]]\n",
      "start point from mess: [148, 192]\n",
      "leftcount: 116\n",
      "start point from mess: [148, 192]\n",
      "al_height: 44\n",
      "start point from mess: [141, 218]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218]]\n",
      "mim_mid\n",
      "start point from mess: [336, 359]\n",
      "leftcount: 91\n",
      "start point from mess: [330, 360]\n",
      "al_height: 30\n",
      "start point from mess: [316, 363]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218], [316, 363]]\n",
      "start point from mess: [288, 320]\n",
      "leftcount: 46\n",
      "start point from mess: [288, 322]\n",
      "al_height: 34\n",
      "start point from mess: [272, 330]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218], [316, 363], [272, 330]]\n",
      "mim_end\n",
      "start point from mess: [589, 617]\n",
      "leftcount: 168\n",
      "start point from mess: [589, 617]\n",
      "al_height: 28\n",
      "start point from mess: [571, 632]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218], [316, 363], [272, 330], [571, 632]]\n",
      "start point from mess: [243, 277]\n",
      "leftcount: 104\n",
      "start point from mess: [245, 277]\n",
      "al_height: 32\n",
      "start point from mess: [243, 301]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218], [316, 363], [272, 330], [571, 632], [243, 301]]\n",
      "[39, 499]\n",
      "2 is not enough\n",
      "[19, 487, 490, 499]\n",
      "4 is not enough\n",
      "[24, 499]\n",
      "2 is not enough\n",
      "[19, 487, 490, 499]\n",
      "4 is not enough\n",
      "[32, 486, 488, 499]\n",
      "4 is not enough\n",
      "[18, 487, 491, 499]\n",
      "4 is not enough\n",
      "[32, 102, 104, 486, 489, 499]\n",
      "[32, 188, 190, 486, 490, 499]\n",
      "[48, 499]\n",
      "2 is not enough\n",
      "[19, 201, 203, 448, 452, 479, 490, 499]\n",
      "False\n",
      "tanwin_1\n",
      "start point from mess: [506, 538]\n",
      "[393, 487, 411, 505]\n",
      "[393, 523, 411, 541]\n",
      "start point from mess: [0, 31]\n",
      "start point from mess: [280, 314]\n",
      "[319, 260, 337, 278]\n",
      "[319, 296, 337, 314]\n",
      "start point from mess: [0, 31]\n",
      "nun_stand\n",
      "start point from mess: [0, 27]\n",
      "start point from mess: [0, 27]\n",
      "dot\n",
      "mim_beg\n",
      "start point from mess: [0, 20]\n",
      "start point from mess: [1, 20]\n",
      "mim_mid\n",
      "start point from mess: [0, 15]\n",
      "start point from mess: [0, 15]\n",
      "mim_end\n",
      "start point from mess: [0, 18]\n",
      "start point from mess: [0, 12]\n",
      "[0, 31]\n",
      "[8, 15]\n",
      "[1, 16]\n",
      "[0, 27]\n",
      "[4, 16]\n",
      "[8, 14]\n",
      "[1, 10]\n",
      "[1, 14]\n",
      "[1, 14]\n",
      "[13, 17]\n",
      "iqlab\n",
      "idgham bilagunnah\n",
      "ikhfa hakiki\n",
      "ikhfa hakiki\n",
      "idzhar syafawi\n",
      "idzhar syafawi\n",
      "idgham mimi\n",
      "idzhar syafawi\n",
      "idgham mimi\n",
      "idgham mimi\n"
     ]
    }
   ],
   "source": [
    "imagePath = '/home/mhbrt/Desktop/Wind/Multiscale/temp/v1.jpg'\n",
    "markerPath = '/home/mhbrt/Desktop/Wind/Multiscale/marker'\n",
    "img = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "res = {'AlKareem': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'AlQalam': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'Amiri': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'KFGQPC': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'LPMQ': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'Norehidayat': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'Norehira': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'Norehuda': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'PDMS': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'meQuran': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10']}\n",
    "# font_list = mess.font(imagePath=imagePath, image=gray, setting=res)\n",
    "font_list, loc_path = flow.font_list(\n",
    "    imagePath=imagePath, image=gray, setting=res, markerPath=markerPath)\n",
    "temp_object = []\n",
    "imagelist_template_matching_result = []\n",
    "imagelist_template_scale_visualize = []\n",
    "imagelist_visualize_white_block = []\n",
    "# print(font_list)\n",
    "# print(font_list[1].marker_location)\n",
    "for font_object in font_list:\n",
    "    font_object.run()\n",
    "    imagelist_template_scale_visualize.append(font_object.imagelist_visualize)\n",
    "    imagelist_visualize_white_block.append(font_object.imagelist_visualize_white_blok)\n",
    "    temp_object.append(font_object.get_object_result())\n",
    "    imagelist_template_matching_result.append(font_object.display_marker_result(img))\n",
    "print(temp_object)\n",
    "final_image_result, normal_processing_result, crop_ratio_processing_result,\\\n",
    "imagelist_horizontal_line_by_eight_conn = flow.big_blok(temp_object, imagePath,\n",
    "                font_object, model, font_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imagelist_template_matching_result\n",
    "# imagelist_template_scale_visualize\n",
    "# imagelist_visualize_white_block[0][7] == []\n",
    "# len(normal_processing_result[1])\n",
    "# crop_ratio_processing_result\n",
    "# imagelist_horizontal_line_by_eight_conn\n",
    "# final_image_result, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 436, 796, 3)\n",
      "(10, 10)\n",
      "(10,)\n",
      "(7,)\n",
      "(0,)\n",
      "(4, 436, 796)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.array(imagelist_template_matching_result).shape)\n",
    "print(np.array(imagelist_template_scale_visualize).shape)\n",
    "print(np.array(imagelist_visualize_white_block).shape)\n",
    "print(np.array(normal_processing_result).shape)\n",
    "print(np.array(crop_ratio_processing_result).shape)\n",
    "print(np.array(imagelist_horizontal_line_by_eight_conn).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for font in imagelist_template_scale_visualize:\n",
    "    for image in font:\n",
    "        cv2.imshow('imagelist_scale_v', image)\n",
    "        cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhbrt/.virtualenvs/tf2/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for font in imagelist_visualize_white_block:\n",
    "    for marker in font:\n",
    "        for image in marker:\n",
    "            if image == []:\n",
    "                continue\n",
    "            cv2.imshow('imagelist_vwb', image)\n",
    "            cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in imagelist_template_matching_result:\n",
    "    cv2.imshow('imagelist_tmr', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in imagelist_horizontal_line_by_eight_conn:\n",
    "    cv2.imshow('imagelist_hlbec', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal processing blok\n",
    "cv2.imshow('horizontal_image', normal_processing_result[6])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for image in normal_processing_result[3]:\n",
    "    cv2.imshow('bag of h with baseline', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for image in normal_processing_result[4]:\n",
    "    cv2.imshow('final body h', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for image in normal_processing_result[5]:\n",
    "    cv2.imshow('final marker h', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for image in normal_processing_result[1]:\n",
    "    cv2.imshow('final word', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for result in normal_processing_result[0]:\n",
    "    for image in result:\n",
    "        cv2.imshow('perchar marker', image)\n",
    "        cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for image in normal_processing_result[2]:\n",
    "    cv2.imshow('final segmented char', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_by_ratio_processing\n",
    "for image in crop_ratio_processing_result[0]:\n",
    "    cv2.imshow('gray image', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for image in crop_ratio_processing_result[1]:\n",
    "    cv2.imshow('eigt conn result on base', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for image in crop_ratio_processing_result[2]:\n",
    "    cv2.imshow('subtrac image', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for image in crop_ratio_processing_result[3]:\n",
    "    cv2.imshow('cutted subtrac img', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "for image in crop_ratio_processing_result[4]:\n",
    "    cv2.imshow('final segmented char', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('imagelist_tmr', final_image_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import pickle\n",
    "sys.path.insert(1, '/home/mhbrt/Desktop/Wind/Multiscale/')\n",
    "import complete_flow as flow\n",
    "\n",
    "# model_name = '/home/mhbrt/Desktop/Wind/Multiscale/Colab/best_model_DenseNet_DD.pkl'\n",
    "# model = pickle.load(open(model_name, 'rb'))\n",
    "# print('_LOAD MODEL DONE_')\n",
    "\n",
    "imagePath = '/home/mhbrt/Desktop/Wind/Multiscale/temp/0v4.jpg'\n",
    "markerPath = '/home/mhbrt/Desktop/Wind/Multiscale/marker'\n",
    "img = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "res = {'AlKareem': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'AlQalam': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'Amiri': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'KFGQPC': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'LPMQ': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'Norehidayat': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'Norehira': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'Norehuda': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'PDMS': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10'], 'meQuran': [['0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7', '0.7'], '10']}\n",
    "# font_list = mess.font(imagePath=imagePath, image=gray, setting=res)\n",
    "font_list, loc_path = flow.font_list(\n",
    "    imagePath=imagePath, image=gray, setting=res, markerPath=markerPath)\n",
    "temp_object = []\n",
    "imagelist_template_matching_result = []\n",
    "imagelist_template_scale_visualize = []\n",
    "print(font_list)\n",
    "# print(font_list[1].marker_location)\n",
    "for font_object in font_list:\n",
    "    font_object.run()\n",
    "    imagelist_template_scale_visualize.append(font_object.imagelist_visualize)\n",
    "    temp_object.append(font_object.get_object_result())\n",
    "    imagelist_template_matching_result.append(font_object.display_marker_result(img))\n",
    "# print(temp_object)\n",
    "# flow.big_blok(temp_object, imagePath,\n",
    "#                 font_object, model, font_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(imagelist_template_scale_visualize[0][0])\n",
    "len(imagelist_template_matching_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    cv2.imshow('sd', imagelist_template_scale_visualize[0][x])\n",
    "#     cv2.imshow('sd', imagelist_template_matching_result[x])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(imagelist_template_matching_result).shape\n",
    "# np.array(imagelist_template_scale_visualize[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import match_prepare as match\n",
    "import copy\n",
    "def normal_image_processing_blok(imagePath, object_result):\n",
    "    original_image = cv2.imread(imagePath)\n",
    "    gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "    # template = cv2.Canny(gray, 50, 200)\n",
    "    # Otsu threshold\n",
    "    ret_img, image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY\n",
    "                                   + cv2.THRESH_OTSU)\n",
    "    # Simple threshold\n",
    "    # ret_img, image2 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    # Adaptive threshold value is the mean of neighbourhood area\n",
    "    # image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    #                               cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Adaptive threshold value is the weighted sum of neighbourhood\n",
    "    # values where weights are a gaussian window\n",
    "#     image = cv2.adaptiveThreshold(gray, 255,\n",
    "#                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "#                                   cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # cv2.imshow('otsu', image1)\n",
    "    # cv2.imshow('simple', image2)\n",
    "    # cv2.imshow('adapt mean', image3)\n",
    "    # cv2.imshow('adapt gaussian', image)\n",
    "    # cv2.waitKey(0)\n",
    "    # image = cv2.bitwise_not(image)\n",
    "    # kernel = np.ones((1,1), np.uint8)\n",
    "    # dilation = cv2.dilate(final_img.copy(),kernel,iterations = 1)\n",
    "    # kernel = np.ones((2,2), np.uint8)\n",
    "    # image = cv2.erode(image,kernel,iterations = 1)\n",
    "    # image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    # image = cv2.bitwise_not(image)\n",
    "    # closing = cv2.morphologyEx(final_img.copy(), cv2.MORPH_CLOSE, kernel)\n",
    "    # cv2.imshow('morph', image)\n",
    "    # print('morph')\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    input_image = match.ImageProcessing(original_image=original_image.copy())\n",
    "    input_image.horizontal_projection(image.copy())  # adaptive binaryimage\n",
    "    horizontal_image = input_image.detect_horizontal_line(\n",
    "        image=original_image.copy(),\n",
    "        pixel_limit_ste=5,  # Start to end\n",
    "        pixel_limit_ets=5   # End to start\n",
    "    )  # Got self.start_point_h\n",
    "    # cv2.imshow('from main', input_image.original_image)\n",
    "    bag_h_original = input_image.start_point_h\n",
    "    input_image.crop_image(h_point=input_image.start_point_h,\n",
    "                           input_image=original_image.copy())  # crop ori\n",
    "\n",
    "#     marker_height_list = []\n",
    "#     font_list = mess.font(imagePath=imagePath, image=gray)\n",
    "#     for font_object in font_list:\n",
    "#         for location in font_object.get_marker_location():\n",
    "#             temp = cv2.imread(location)\n",
    "#             h, _, _ = temp.shape\n",
    "#             marker_height_list.append(h)\n",
    "#     print(marker_height_list)\n",
    "    # Block font processing\n",
    "    count = 0\n",
    "    save_state = {}\n",
    "    imagelist_bag_of_h_with_baseline = []\n",
    "    imagelist_image_final_body = []\n",
    "    imagelist_image_final_marker = []\n",
    "    imagelist_perchar_marker = []\n",
    "    imagelist_final_word_img = []\n",
    "    imagelist_final_segmented_char = []\n",
    "    for image in input_image.bag_of_h_crop:\n",
    "        # Get original cropped one line binary image\n",
    "        temp_image_ori = input_image.bag_of_h_crop[image]\n",
    "        h, _, _ = temp_image_ori.shape\n",
    "        # Scaled image by height ratio\n",
    "#         scaled_one_line_img_size = 1.3 * max(marker_height_list)\n",
    "#         if h > scaled_one_line_img_size:\n",
    "#             scale = scaled_one_line_img_size / h\n",
    "#             temp_image_ori = imutils.resize(temp_image_ori,\n",
    "#                                             height=int(h * scale))\n",
    "#         else:\n",
    "#             scale = 1\n",
    "#         if scale != 1:\n",
    "#             print('Scalling image to ' + str(scale))\n",
    "#         scale = 0.9285714285714286\n",
    "#         temp_image_ori = imutils.resize(temp_image_ori,\n",
    "#                                             height=int(h * scale))\n",
    "        scale = 1\n",
    "        gray = cv2.cvtColor(temp_image_ori, cv2.COLOR_BGR2GRAY)\n",
    "        temp_image = cv2.adaptiveThreshold(gray, 255,\n",
    "                                           cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                           cv2.THRESH_BINARY, 11, 2)\n",
    "        # temp_image = temp_image_ori\n",
    "        # Calculate base line processing from self.h_projection\n",
    "        input_image.horizontal_projection(temp_image.copy())\n",
    "        input_image.base_line(one_line_image=temp_image_ori)\n",
    "        oneline_baseline = []\n",
    "        oneline_baseline.append(input_image.base_start)\n",
    "        oneline_baseline.append(input_image.base_end)\n",
    "        if oneline_baseline[1] < oneline_baseline[0]:\n",
    "            temp = oneline_baseline[0]\n",
    "            oneline_baseline[0] = oneline_baseline[1]\n",
    "            oneline_baseline[1] = temp\n",
    "        imagelist_bag_of_h_with_baseline.append(input_image.one_line_image)\n",
    "#         cv2.imshow('Base start =' + str(input_image.base_start)\n",
    "#                    + ' end =' + str(input_image.base_end),\n",
    "#                    input_image.one_line_image)\n",
    "#         print('>')\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyWindow('Base start =' + str(input_image.base_start)\n",
    "#                           + ' end =' + str(input_image.base_end))\n",
    "\n",
    "        # Font_Processing\n",
    "#         font_list = font(imagePath=imagePath, image=gray)\n",
    "#         max_font_value = 0\n",
    "#         font_type = 0\n",
    "#         numstep = 20\n",
    "        # Looking for font type by the greatest value\n",
    "#         for font_object in font_list:\n",
    "#             font_object.run(numstep=numstep)\n",
    "#             for value in font_object.get_object_result().values():\n",
    "#                 # print(value)\n",
    "#                 if type(value) == float:\n",
    "#                     if value > max_font_value:\n",
    "#                         max_font_value = value\n",
    "#                         font_type = font_object\n",
    "        not_empty = False\n",
    "        for data in object_result:\n",
    "            if isinstance(object_result[data], type(np.array([]))):\n",
    "                not_empty = True\n",
    "                break\n",
    "\n",
    "        if not_empty:\n",
    "            print('into eight connectivity')\n",
    "            input_image.eight_connectivity(\n",
    "                temp_image.copy(), oneline_baseline\n",
    "            )\n",
    "            conn_pack_sorted = copy.deepcopy(\n",
    "                input_image.conn_pack_sorted\n",
    "            )\n",
    "            conn_pack_minus_body = copy.deepcopy(\n",
    "                input_image.conn_pack_minus_body\n",
    "            )\n",
    "            imagelist_image_final_body.append(input_image.image_final_sorted)\n",
    "            imagelist_image_final_marker.append(input_image.image_final_marker)\n",
    "            # font_type.display_marker_result(input_image=temp_image_ori)\n",
    "        else:\n",
    "            object_result = False\n",
    "            print('Not a valuable result found check the numstep!')\n",
    "            continue\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "        # Crop next word marker wether it's inside or beside\n",
    "        crop_words = {}\n",
    "        if object_result:\n",
    "            # Grouping marker by its v_projection\n",
    "            input_image.grouping_marker()\n",
    "            group_marker_by_wall = copy.deepcopy(\n",
    "                input_image.group_marker_by_wall\n",
    "            )\n",
    "#             print('bw:', group_marker_by_wall)\n",
    "#             print('bw1:', conn_pack_sorted)\n",
    "#             print('bw2:', conn_pack_minus_body)\n",
    "#             print(object_result)\n",
    "#             cv2.waitKey(0)\n",
    "            for data in object_result:\n",
    "                if isinstance(object_result[data], type(np.array([]))):\n",
    "                    temp_x = object_result[data]\n",
    "                    part = data.split('_')\n",
    "                    name = []\n",
    "                    for x in range(len(part)):\n",
    "                        if x == 0:\n",
    "                            continue\n",
    "                        if x == len(part) - 1:\n",
    "                            name.append(part[x])\n",
    "                        else:\n",
    "                            name.append(part[x] + '_')\n",
    "                    name = ''.join(name)\n",
    "                    # crop_words['ordinat_' + name]=temp_x\n",
    "                    for arr in range(len(temp_x)):\n",
    "                        y1 = (temp_x)[arr][1]\n",
    "                        y2 = (temp_x)[arr][3]\n",
    "                        if bag_h_original[image] <= y1 <= bag_h_original[image+1]:\n",
    "                            #                             print('pass')\n",
    "                            print('processing:', name)\n",
    "                            pass\n",
    "                        else:\n",
    "                            #                             print('continue')\n",
    "                            continue\n",
    "                        x2 = (temp_x)[arr][2]  # x2 is on the right\n",
    "                        x1 = (temp_x)[arr][0]  # x1 is on the left\n",
    "                        width_x = x2-x1\n",
    "                        mid_x = x1 + round((x2 - x1)/2)  # x in the middle\n",
    "#                         print('ordinat ' + data + '={}'.format(x))\n",
    "                        # marker_width = (temp_x[arr][2]) - x\n",
    "                        wall_count = -1\n",
    "                        for wall in group_marker_by_wall:\n",
    "                            wall_count += 1\n",
    "                            if wall[0] <= mid_x <= wall[1]:\n",
    "                                break\n",
    "#                         cv2.waitKey(0)\n",
    "                        wall = group_marker_by_wall.keys()\n",
    "                        wall = list(wall)\n",
    "                        ####\n",
    "                        # print(group_marker_by_wall, wall_count)\n",
    "                        ####\n",
    "                        found_in_wall = False\n",
    "                        for region in group_marker_by_wall[\n",
    "                                wall[wall_count]]:\n",
    "                            if found_in_wall:\n",
    "                                break\n",
    "                            region_yx = conn_pack_minus_body[\n",
    "                                region]\n",
    "                            for y_x in region_yx:\n",
    "                                if y_x[1] < x1 - width_x:\n",
    "                                    print('add inside wall')\n",
    "                                    crop_words['final_inside_' + name\n",
    "                                               + '_' + str(arr)] \\\n",
    "                                        = wall[wall_count]\n",
    "                                    crop_words['ordinat_' + name\n",
    "                                               + '_' + str(arr)] \\\n",
    "                                        = temp_x[arr]\n",
    "                                    found_in_wall = True\n",
    "                                    break\n",
    "                        if not found_in_wall:\n",
    "                            if wall_count > 0:\n",
    "                                next_wall = wall[wall_count - 1]\n",
    "                                found_next_wall = False\n",
    "                                if group_marker_by_wall[next_wall] != []:\n",
    "                                    print('add next wall')\n",
    "                                    crop_words['final_beside_'\n",
    "                                               + name + '_' + str(arr)] \\\n",
    "                                        = next_wall\n",
    "                                    crop_words['ordinat_' + name\n",
    "                                               + '_' + str(arr)] \\\n",
    "                                        = temp_x[arr]\n",
    "                                    found_next_wall = True\n",
    "                                if not found_next_wall and wall_count > 1:\n",
    "                                    beside_next_wall = wall[wall_count - 2]\n",
    "                                    if group_marker_by_wall[\n",
    "                                            beside_next_wall] != []:\n",
    "                                        print('add beside next wall')\n",
    "                                        crop_words['final_beside_'\n",
    "                                                   + name + '_'\n",
    "                                                   + str(arr)] \\\n",
    "                                            = beside_next_wall\n",
    "                                        crop_words['ordinat_' + name\n",
    "                                                   + '_' + str(arr)] \\\n",
    "                                            = temp_x[arr]\n",
    "\n",
    "#             font_type.display_marker_result(input_image=temp_image_ori)\n",
    "\n",
    "        # Looking for final segmented character\n",
    "        # print(crop_words_final)\n",
    "        # for key in crop_words_final:\n",
    "        \n",
    "        print('CROP WORDS = ', crop_words)\n",
    "        for key in crop_words:\n",
    "            name = key.split('_')\n",
    "            if name[0] == 'final':\n",
    "                save_state[count] = []\n",
    "                count += 1\n",
    "                # x_value = crop_words_final[key]\n",
    "                x_value = crop_words[key]\n",
    "                # print(x_value)\n",
    "                join = []\n",
    "                for x in range(len(name)):\n",
    "                    if x == 0:\n",
    "                        continue\n",
    "                    if x == 1:\n",
    "                        continue\n",
    "                    if x == len(name) - 1:\n",
    "                        join.append(name[x])\n",
    "                        # print(name[x])\n",
    "                    else:\n",
    "                        join.append(name[x] + '_')\n",
    "                        # print(name[x])\n",
    "                join = ''.join(join)\n",
    "                save_state[count-1].append(join)\n",
    "                print('join = {}'.format(join))\n",
    "\n",
    "                # List available for final segmented char\n",
    "                final_segmented_char = temp_image.copy()\n",
    "                final_segmented_char[:] = 255\n",
    "                if name[1] == 'beside':\n",
    "                    # final_img = temp_image.copy()[:, x_value[0]:x_value[1]]\n",
    "                    final_img = input_image.image_join.copy()[\n",
    "                        :, x_value[0]:x_value[1]]\n",
    "                    w_height, w_width = final_img.shape\n",
    "#                     cv2.imshow('beside', final_img)\n",
    "                    final_segmented_char, pass_x1 = input_image.find_final_processed_char(\n",
    "                        x_value, oneline_baseline\n",
    "                    )\n",
    "                    if final_segmented_char == 'continue':\n",
    "                        print(\n",
    "                            '>> from main to continue next word candidate'\n",
    "                        )\n",
    "                        continue\n",
    "                    else:\n",
    "                        save_state[count-1].append(scale)\n",
    "                        save_state[count-1].append(bag_h_original[image])\n",
    "                        save_state[count-1].append(\n",
    "                            crop_words['ordinat_' + join]\n",
    "                        )\n",
    "                        save_state[count-1].append(final_segmented_char)\n",
    "                        save_state[count-1].append(pass_x1)\n",
    "\n",
    "                if name[1] == 'inside':\n",
    "                    x1_ordinat = crop_words['ordinat_' + join][0]\n",
    "                    # x1_ordinat = crop_words_final['ordinat_' + join][0]\n",
    "                    # Cut before the detected char marker\n",
    "#                     print('x1_ordinat = {}'.format(x1_ordinat))\n",
    "#                     cv2.waitKey(0)\n",
    "                    # final_img = temp_image.copy()[:, x_value[0]:x1_ordinat]\n",
    "                    final_img = input_image.image_join.copy()[\n",
    "                        :, x_value[0]:x1_ordinat]\n",
    "                    w_height, w_width = final_img.shape\n",
    "#                     cv2.imshow('inside', final_img)\n",
    "                    final_wall = (x_value[0], x1_ordinat)\n",
    "                    final_segmented_char, pass_x1 = input_image.find_final_processed_char(\n",
    "                        final_wall, oneline_baseline\n",
    "                    )\n",
    "                    if final_segmented_char == 'continue':\n",
    "                        print(\n",
    "                            '>> from main to continue next word candidate'\n",
    "                        )\n",
    "                        continue\n",
    "                    else:\n",
    "                        save_state[count-1].append(scale)\n",
    "                        save_state[count-1].append(bag_h_original[image])\n",
    "                        save_state[count-1].append(\n",
    "                            crop_words['ordinat_' + join]\n",
    "                        )\n",
    "                        save_state[count-1].append(final_segmented_char)\n",
    "                        save_state[count-1].append(pass_x1)\n",
    "                \n",
    "                imagelist_perchar_marker.append(input_image.imagelist_perchar_marker)\n",
    "                # print('_________________________________', imagelist_perchar_marker)\n",
    "                imagelist_final_word_img.append(final_img)\n",
    "                # print('sd', imagelist_final_word_img)\n",
    "                imagelist_final_segmented_char.append(final_segmented_char)\n",
    "                # print('l', imagelist_final_segmented_char)\n",
    "\n",
    "    return save_state, imagelist_perchar_marker, imagelist_final_word_img, imagelist_final_segmented_char,\\\n",
    "         imagelist_bag_of_h_with_baseline, imagelist_image_final_body, imagelist_image_final_marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_state, imagelist_perchar_marker, imagelist_final_word_img, imagelist_final_segmented_char,\\\n",
    "imagelist_bag_of_h_with_baseline, imagelist_image_final_body, imagelist_image_final_marker = normal_image_processing_blok(\n",
    "            imagePath, temp_object[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in imagelist_perchar_marker:\n",
    "    for image in char:\n",
    "        cv2.imshow('imagelist_hlbec', image)\n",
    "        cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in imagelist_final_word_img:\n",
    "    cv2.imshow('imagelist_hlbec', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in imagelist_final_segmented_char:\n",
    "    cv2.imshow('imagelist_hlbec', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in imagelist_bag_of_h_with_baseline:\n",
    "    cv2.imshow('imagelist_hlbec', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in imagelist_image_final_body:\n",
    "    cv2.imshow('imagelist_hlbec', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in imagelist_image_final_marker:\n",
    "    cv2.imshow('imagelist_hlbec', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelist_bag_of_h_with_baseline[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    return max(set(List), key=List.count)\n",
    "\n",
    "def horizontal_projection(image_h):\n",
    "    image = image_h.copy()\n",
    "    image[image < 127] = 1\n",
    "    image[image >= 127] = 0\n",
    "    h_projection = np.sum(image, axis=1)\n",
    "\n",
    "    return h_projection\n",
    "\n",
    "\n",
    "def detect_horizontal_line(h_projection, pixel_limit_ste, pixel_limit_ets):\n",
    "    # Detect line horizontal\n",
    "    up_flag = 0\n",
    "    down_flag = 0\n",
    "    # pixel_limit = 5\n",
    "    start_to_end = 0\n",
    "    end_to_start = pixel_limit_ets + 1\n",
    "    start_point = []\n",
    "    for x in range(len(h_projection)):\n",
    "        if h_projection[x] > 0 and up_flag == 1:\n",
    "            start_to_end += 1\n",
    "\n",
    "        if h_projection[x] == 0 and up_flag == 1:\n",
    "            # print(start_to_end)\n",
    "            start_point.append(x)\n",
    "            # print(start_point)\n",
    "            if start_to_end < pixel_limit_ste:\n",
    "                del(start_point[len(start_point) - 1])\n",
    "                # print('delete ste')\n",
    "                down_flag = 0\n",
    "                up_flag = 1\n",
    "            else:\n",
    "                down_flag = 1\n",
    "                up_flag = 0\n",
    "                start_to_end = 0\n",
    "\n",
    "        if h_projection[x] == 0 and down_flag == 1:\n",
    "            end_to_start += 1\n",
    "\n",
    "        if h_projection[x] > 0 and up_flag == 0:\n",
    "            start_point.append(x)\n",
    "            # print(start_point)\n",
    "            if end_to_start < pixel_limit_ets:\n",
    "                del(start_point[len(start_point)-1])\n",
    "                del(start_point[len(start_point)-1])\n",
    "            up_flag = 1\n",
    "            down_flag = 0\n",
    "            end_to_start = 0\n",
    "\n",
    "    if len(start_point) % 2 != 0:\n",
    "        if h_projection[len(h_projection) - 1] > 0:\n",
    "            start_point.append(len(h_projection) - 1)\n",
    "\n",
    "    return start_point\n",
    "\n",
    "\n",
    "# #### used by image processing stage\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def get_ul_coordinat(coordinat, height, ht_overide=0):\n",
    "    if ht_overide > 0:\n",
    "        height_tanwin = ht_overide\n",
    "    else:\n",
    "        height_tanwin = coordinat[3] - coordinat[1]\n",
    "    # upper\n",
    "    if coordinat[1]-height_tanwin > 0:\n",
    "        upper = [coordinat[0], coordinat[1]-height_tanwin,\n",
    "                 coordinat[2], coordinat[3]-height_tanwin]\n",
    "    else:\n",
    "        upper = [coordinat[0], 0,\n",
    "                 coordinat[2], coordinat[3]-height_tanwin]\n",
    "    # lower\n",
    "    if coordinat[3]+height_tanwin < height:\n",
    "        lower = [coordinat[0], coordinat[1]+height_tanwin,\n",
    "                 coordinat[2], coordinat[3]+height_tanwin]\n",
    "    else:\n",
    "        lower = [coordinat[0], coordinat[1]+height_tanwin,\n",
    "                 coordinat[2], height-1]\n",
    "\n",
    "    return upper, lower\n",
    "\n",
    "\n",
    "def upper_or_lower(bw_img, upper, lower):\n",
    "    upper_count = 0\n",
    "    for x in range(upper[0], upper[2]):\n",
    "        for y in range(upper[1], upper[3]):\n",
    "            if bw_img[y, x] < 1:\n",
    "                upper_count += 1\n",
    "\n",
    "    lower_count = 0\n",
    "    for x in range(lower[0], lower[2]):\n",
    "        for y in range(lower[1], lower[3]):\n",
    "            if bw_img[y, x] < 1:\n",
    "                lower_count += 1\n",
    "\n",
    "    return upper_count, lower_count\n",
    "\n",
    "\n",
    "def get_lr_coordinat(coordinat, width):\n",
    "    width_tanwin = coordinat[2] - coordinat[0]\n",
    "    if coordinat[0] - width_tanwin > 0:\n",
    "        left = [coordinat[0]-width_tanwin, coordinat[1],\n",
    "                coordinat[2]-width_tanwin, coordinat[3]]\n",
    "    else:\n",
    "        left = [0, coordinat[1],\n",
    "                coordinat[2]-width_tanwin, coordinat[3]]\n",
    "    if coordinat[2] + width_tanwin < width:\n",
    "        right = [coordinat[0]+width_tanwin, coordinat[1],\n",
    "                 coordinat[2]+width_tanwin, coordinat[3]]\n",
    "    else:\n",
    "        right = [coordinat[0]+width_tanwin, coordinat[1],\n",
    "                 width-1, coordinat[3]]\n",
    "\n",
    "    return left, right\n",
    "\n",
    "\n",
    "def black_pixel_count(bw_img, lower):\n",
    "    lower_count = 0\n",
    "    for x in range(lower[0], lower[2]):\n",
    "        for y in range(lower[1], lower[3]):\n",
    "            if bw_img[y, x] < 1:\n",
    "                lower_count += 1\n",
    "\n",
    "    return lower_count\n",
    "\n",
    "\n",
    "def get_marker_name(key):\n",
    "    part = key.split('_')\n",
    "    name = []\n",
    "    for x in range(len(part)):\n",
    "        if x == 0:\n",
    "            continue\n",
    "        if x == len(part) - 1:\n",
    "            name.append(part[x])\n",
    "        else:\n",
    "            name.append(part[x] + '_')\n",
    "    name = ''.join(name)\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def region_tanwin(coordinat, image, font_list, view=True):\n",
    "    saved_tanwin_height = coordinat[3] - coordinat[1]\n",
    "    font_object = font_list[0]\n",
    "    h, w, = image.shape\n",
    "\n",
    "    marker_only_count = black_pixel_count(image, coordinat)\n",
    "\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), coordinat,\n",
    "                                              left=False, right=False)\n",
    "    image_process = image.copy()\n",
    "    image_process[:] = 255\n",
    "    for region in con_pack:\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    font_object.horizontal_projection(image_process)\n",
    "    h_image = font_object.detect_horizontal_line(image.copy(), 0, 0)\n",
    "    start_point_h = font_object.start_point_h\n",
    "    font_object.vertical_projection(image_process)\n",
    "    h_image = font_object.detect_vertical_line(image.copy(), 0)\n",
    "    start_point_v = font_object.start_point_v\n",
    "\n",
    "    coordinat_candidate = [start_point_v[0], start_point_h[0],\n",
    "                           start_point_v[1], start_point_h[1]]\n",
    "    cc_count = black_pixel_count(image, coordinat_candidate)\n",
    "\n",
    "    if cc_count < 2 * marker_only_count:\n",
    "        coordinat = coordinat_candidate\n",
    "\n",
    "    cv2.rectangle(image_process, (coordinat[0], coordinat[1]),\n",
    "                  (coordinat[2], coordinat[3]), (0, 255, 0), 2)\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    upper, lower = get_ul_coordinat(coordinat, h)\n",
    "    print(upper)\n",
    "    print(lower)\n",
    "    upper_count, lower_count = upper_or_lower(image, upper, lower)\n",
    "\n",
    "    if upper_count < lower_count:\n",
    "        cv2.rectangle(image_process, (lower[0], lower[1]),\n",
    "                      (lower[2], lower[3]), (100, 150, 0), 2)\n",
    "        region = lower\n",
    "    elif upper_count > lower_count:\n",
    "        cv2.rectangle(image_process, (upper[0], upper[1]),\n",
    "                      (upper[2], upper[3]), (100, 150, 0), 2)\n",
    "        region = upper\n",
    "    else:\n",
    "        print('enlarge')\n",
    "        while(upper_count == lower_count):\n",
    "            upper, _ = get_ul_coordinat(upper, h)\n",
    "            _, lower = get_ul_coordinat(lower, h)\n",
    "            upper_count, lower_count = upper_or_lower(image, upper, lower)\n",
    "            if upper_count < lower_count:\n",
    "                cv2.rectangle(image_process, (lower[0], lower[1]),\n",
    "                              (lower[2], lower[3]), (100, 150, 0), 2)\n",
    "                region = lower\n",
    "            elif upper_count > lower_count:\n",
    "                cv2.rectangle(image_process, (upper[0], upper[1]),\n",
    "                              (upper[2], upper[3]), (100, 150, 0), 2)\n",
    "                region = upper\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    return region\n",
    "\n",
    "\n",
    "def raw_baseline(image_b, font_object):\n",
    "    #     image_b = bw_image[oneline_coordinat[0]:oneline_coordinat[1], :]\n",
    "    font_object.horizontal_projection(image_b)\n",
    "    font_object.base_line(image_b)\n",
    "    oneline_baseline = []\n",
    "    oneline_baseline.append(font_object.base_start)\n",
    "    oneline_baseline.append(font_object.base_end)\n",
    "    if oneline_baseline[1] < oneline_baseline[0]:\n",
    "        temp = oneline_baseline[0]\n",
    "        oneline_baseline[0] = oneline_baseline[1]\n",
    "        oneline_baseline[1] = temp\n",
    "    oneline_image = font_object.one_line_image\n",
    "    # cv2.imshow('line', oneline_image)\n",
    "    # print('>')\n",
    "\n",
    "    return oneline_baseline\n",
    "\n",
    "\n",
    "# #### eight_conn_by_seed_tanwin\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def eight_conn_by_seed_tanwin(coordinat, img, font_list, view=True):\n",
    "    saved_tanwin_height = coordinat[3] - coordinat[1]\n",
    "    font_object = font_list[0]\n",
    "    h, w, _ = img.shape\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     coordinat = [ 98, 625, 109, 640]\n",
    "    # mid_seed = coordinat[1] + int((coordinat[3]-coordinat[1])/2)\n",
    "    # seed = [0, mid_seed, w, mid_seed+1]\n",
    "    # Otsu threshold\n",
    "    # ret_img, image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY\n",
    "    #                                 + cv2.THRESH_OTSU)\n",
    "    # Simple threshold\n",
    "    # ret_img, image = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    # Adaptive threshold value is the mean of neighbourhood area\n",
    "    # image = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    #                               cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Adaptive threshold value is the weighted sum of neighbourhood\n",
    "    # values where weights are a gaussian window\n",
    "    image = cv2.adaptiveThreshold(gray, 255,\n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                  cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    marker_only_count = black_pixel_count(image, coordinat)\n",
    "\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), coordinat,\n",
    "                                              left=False, right=False)\n",
    "    image_process = image.copy()\n",
    "    image_process[:] = 255\n",
    "    for region in con_pack:\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    font_object.horizontal_projection(image_process)\n",
    "    h_image = font_object.detect_horizontal_line(image.copy(), 0, 0)\n",
    "    start_point_h = font_object.start_point_h\n",
    "    font_object.vertical_projection(image_process)\n",
    "    h_image = font_object.detect_vertical_line(image.copy(), 0)\n",
    "    start_point_v = font_object.start_point_v\n",
    "\n",
    "    coordinat_candidate = [start_point_v[0], start_point_h[0],\n",
    "                           start_point_v[1], start_point_h[1]]\n",
    "    cc_count = black_pixel_count(image, coordinat_candidate)\n",
    "\n",
    "    if cc_count < 2 * marker_only_count:\n",
    "        coordinat = coordinat_candidate\n",
    "\n",
    "    cv2.rectangle(image_process, (coordinat[0], coordinat[1]),\n",
    "                  (coordinat[2], coordinat[3]), (0, 255, 0), 2)\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    upper, lower = get_ul_coordinat(coordinat, h)\n",
    "    print(upper)\n",
    "    print(lower)\n",
    "    upper_count, lower_count = upper_or_lower(image, upper, lower)\n",
    "\n",
    "    if upper_count < lower_count:\n",
    "        print('lower')\n",
    "        left, right = get_lr_coordinat(lower, w)\n",
    "        con_pack = font_object.eight_connectivity(image.copy(), lower,\n",
    "                                                  left=False, right=False)\n",
    "        for region in con_pack:\n",
    "            for val in con_pack[region]:\n",
    "                image_process[val] = 0\n",
    "        cv2.rectangle(image_process, (lower[0], lower[1]),\n",
    "                      (lower[2], lower[3]), (100, 150, 0), 2)\n",
    "    elif upper_count > lower_count:\n",
    "        print('upper')\n",
    "        left, right = get_lr_coordinat(upper, w)\n",
    "        con_pack = font_object.eight_connectivity(image.copy(), upper,\n",
    "                                                  left=False, right=False)\n",
    "        for region in con_pack:\n",
    "            for val in con_pack[region]:\n",
    "                image_process[val] = 0\n",
    "        cv2.rectangle(image_process, (upper[0], upper[1]),\n",
    "                      (upper[2], upper[3]), (100, 150, 0), 2)\n",
    "    else:\n",
    "        print('enlarge')\n",
    "        while(upper_count == lower_count):\n",
    "            upper, _ = get_ul_coordinat(upper, h)\n",
    "            _, lower = get_ul_coordinat(lower, h)\n",
    "            upper_count, lower_count = upper_or_lower(image, upper, lower)\n",
    "            if upper_count < lower_count:\n",
    "                left, right = get_lr_coordinat(lower, w)\n",
    "                con_pack = font_object.eight_connectivity(image.copy(), lower,\n",
    "                                                          left=False, right=False)\n",
    "                for region in con_pack:\n",
    "                    for val in con_pack[region]:\n",
    "                        image_process[val] = 0\n",
    "                cv2.rectangle(image_process, (lower[0], lower[1]),\n",
    "                              (lower[2], lower[3]), (100, 150, 0), 2)\n",
    "            elif upper_count > lower_count:\n",
    "                left, right = get_lr_coordinat(upper, w)\n",
    "                con_pack = font_object.eight_connectivity(image.copy(), upper,\n",
    "                                                          left=False, right=False)\n",
    "                for region in con_pack:\n",
    "                    for val in con_pack[region]:\n",
    "                        image_process[val] = 0\n",
    "                cv2.rectangle(image_process, (upper[0], upper[1]),\n",
    "                              (upper[2], upper[3]), (100, 150, 0), 2)\n",
    "\n",
    "    left_count, _ = upper_or_lower(image, left, right)\n",
    "    while(left_count < 2):\n",
    "        left, _ = get_lr_coordinat(left, w)\n",
    "        left_count, _ = upper_or_lower(image, left, right)\n",
    "        if left[0] < 1:\n",
    "            break\n",
    "    cv2.rectangle(image_process, (left[0], left[1]),\n",
    "                  (left[2], left[3]), (100, 150, 0), 2)\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), left,\n",
    "                                              left=False, right=False)\n",
    "    max_left_region = 0\n",
    "    for region in con_pack:\n",
    "        #         print(con_pack[region])\n",
    "        #         print(region)\n",
    "        if len(con_pack[region]) > max_left_region:\n",
    "            max_left_region = len(con_pack[region])\n",
    "            print(max_left_region)\n",
    "        for val in con_pack[region]:\n",
    "            #             print(region)\n",
    "            #             print(val)\n",
    "            image_process[val] = 0\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    image_process_after_left = image.copy()\n",
    "    image_process_after_left[:] = 255\n",
    "    for region in con_pack:\n",
    "        for val in con_pack[region]:\n",
    "            image_process_after_left[val] = 0\n",
    "    font_object.horizontal_projection(image_process_after_left)\n",
    "    h_image_al = font_object.detect_horizontal_line(image.copy(), 0, 0)\n",
    "    start_point_h_al = font_object.start_point_h\n",
    "    coordinat_al = [0, start_point_h_al[0], w, start_point_h_al[1]]\n",
    "\n",
    "    cv2.rectangle(image_process_after_left, (coordinat_al[0], coordinat_al[1]),\n",
    "                  (coordinat_al[2], coordinat_al[3]), (0, 255, 0), 2)\n",
    "    if view:\n",
    "        cv2.imshow('d_al', image_process_after_left)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    left = [left[0], start_point_h_al[0], left[2], start_point_h_al[1]]\n",
    "    cv2.rectangle(image_process, (left[0], left[1]),\n",
    "                  (left[2], left[3]), (100, 150, 0), 2)\n",
    "\n",
    "    upper, lower = get_ul_coordinat(left, h, saved_tanwin_height)\n",
    "#     cv2.rectangle(image_process, (lower[0], lower[1]),\n",
    "#                           (lower[2], lower[3]), (100, 150,0), 2)\n",
    "#     cv2.rectangle(image_process, (upper[0], upper[1]),\n",
    "#                           (upper[2], upper[3]), (100, 150,0), 2)\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), upper,\n",
    "                                              left=False, right=False)\n",
    "#     max_left_region = 30\n",
    "    for region in con_pack:\n",
    "        if len(con_pack[region]) > max_left_region:\n",
    "            continue\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), lower,\n",
    "                                              left=False, right=False)\n",
    "    for region in con_pack:\n",
    "        if len(con_pack[region]) > max_left_region:\n",
    "            continue\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "############################\n",
    "#     left_count_mod = black_pixel_count(image, left)\n",
    "    left_count_mod = 100\n",
    "    left, _ = get_lr_coordinat(left, w)\n",
    "    left_count = black_pixel_count(image, left)\n",
    "    while(left_count < 2):\n",
    "        left, _ = get_lr_coordinat(left, w)\n",
    "        left_count = black_pixel_count(image, left)\n",
    "        if left[0] < 1:\n",
    "            break\n",
    "    cv2.rectangle(image_process, (left[0], left[1]),\n",
    "                  (left[2], left[3]), (100, 150, 0), 2)\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), left,\n",
    "                                              left=False, right=False)\n",
    "    for region in con_pack:\n",
    "        if len(con_pack[region]) > 2 * left_count_mod:\n",
    "            continue\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    left, _ = get_lr_coordinat(left, w)\n",
    "    left_count = black_pixel_count(image, left)\n",
    "    while(left_count < 2):\n",
    "        left, _ = get_lr_coordinat(left, w)\n",
    "        left_count = black_pixel_count(image, left)\n",
    "        if left[0] < 1:\n",
    "            break\n",
    "    cv2.rectangle(image_process, (left[0], left[1]),\n",
    "                  (left[2], left[3]), (100, 150, 0), 2)\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), left,\n",
    "                                              left=False, right=False)\n",
    "    for region in con_pack:\n",
    "        if len(con_pack[region]) > 2 * left_count_mod:\n",
    "            continue\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "##########################\n",
    "\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), right,\n",
    "                                              left=False, right=False)\n",
    "    for region in con_pack:\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    font_object.horizontal_projection(image_process)\n",
    "    al_height = start_point_h_al[1]-start_point_h_al[0]\n",
    "    print('al_height:', al_height)\n",
    "    h_image = font_object.detect_horizontal_line(image.copy(), al_height, 5)\n",
    "    start_point_h = font_object.start_point_h\n",
    "    if view:\n",
    "        cv2.imshow('line', h_image)\n",
    "        cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    return start_point_h, image_process\n",
    "\n",
    "\n",
    "# #### eight_conn_by_seed\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def eight_conn_by_seed(coordinat, img, font_list, view=True):\n",
    "    saved_starting_height = coordinat[3] - coordinat[1]\n",
    "    font_object = font_list[0]\n",
    "    h, w, _ = img.shape\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     coordinat = [ 98, 625, 109, 640]\n",
    "    # mid_seed = coordinat[1] + int((coordinat[3]-coordinat[1])/2)\n",
    "    # seed = [0, mid_seed, w, mid_seed+1]\n",
    "    # Otsu threshold\n",
    "    # ret_img, image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY\n",
    "    #                                 + cv2.THRESH_OTSU)\n",
    "    # Simple threshold\n",
    "    # ret_img, image = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    # Adaptive threshold value is the mean of neighbourhood area\n",
    "    # image = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    #                               cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Adaptive threshold value is the weighted sum of neighbourhood\n",
    "    # values where weights are a gaussian window\n",
    "    image = cv2.adaptiveThreshold(gray, 255,\n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                  cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    marker_only_count = black_pixel_count(image, coordinat)\n",
    "\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), coordinat,\n",
    "                                              left=False, right=False)\n",
    "    max_y_start = 0\n",
    "    min_y_start = 10000\n",
    "    for region in con_pack:\n",
    "        for val in con_pack[region]:\n",
    "            if val[0] > max_y_start:\n",
    "                max_y_start = val[0]\n",
    "            if val[0] < min_y_start:\n",
    "                min_y_start = val[0]\n",
    "\n",
    "    starting_height = coordinat[3] - coordinat[1]\n",
    "    sch_a = max_y_start - coordinat[1]\n",
    "    sch_b = coordinat[3] - min_y_start\n",
    "\n",
    "    if sch_a > sch_b:\n",
    "        starting_conpack_height = sch_a\n",
    "    else:\n",
    "        starting_conpack_height = sch_b\n",
    "\n",
    "    image_process = image.copy()\n",
    "    image_process[:] = 255\n",
    "    if starting_conpack_height < 2 * starting_height:\n",
    "        for region in con_pack:\n",
    "            for val in con_pack[region]:\n",
    "                image_process[val] = 0\n",
    "        if view:\n",
    "            cv2.imshow('d', image_process)\n",
    "            cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "        font_object.horizontal_projection(image_process)\n",
    "        h_image = font_object.detect_horizontal_line(\n",
    "            image.copy(), starting_height, 0)\n",
    "        start_point_h = font_object.start_point_h\n",
    "        font_object.vertical_projection(image_process)\n",
    "        h_image = font_object.detect_vertical_line(image.copy(), 0)\n",
    "        start_point_v = font_object.start_point_v\n",
    "\n",
    "        coordinat_candidate = [start_point_v[0], start_point_h[0],\n",
    "                               start_point_v[1], start_point_h[1]]\n",
    "        cc_count = black_pixel_count(image, coordinat_candidate)\n",
    "\n",
    "        if cc_count < 2 * marker_only_count:\n",
    "            print('replace coordinat')\n",
    "            coordinat = coordinat_candidate\n",
    "\n",
    "    cv2.rectangle(image_process, (coordinat[0], coordinat[1]),\n",
    "                  (coordinat[2], coordinat[3]), (0, 255, 0), 2)\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    coordinat, right = get_lr_coordinat(coordinat, w)\n",
    "\n",
    "    left_count = black_pixel_count(image, coordinat)\n",
    "    print('leftcount:', left_count)\n",
    "    while(left_count < 2):\n",
    "        coordinat, _ = get_lr_coordinat(coordinat, w)\n",
    "        left_count = black_pixel_count(image, coordinat)\n",
    "        print('leftcount:', left_count)\n",
    "    left = coordinat\n",
    "\n",
    "    cv2.rectangle(image_process, (left[0], left[1]),\n",
    "                  (left[2], left[3]), (100, 150, 0), 2)\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), left,\n",
    "                                              left=False, right=False)\n",
    "    max_left_region = 0\n",
    "    for region in con_pack:\n",
    "        if len(con_pack[region]) > max_left_region:\n",
    "            max_left_region = len(con_pack[region])\n",
    "#             print(max_left_region)\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    image_process_after_left = image.copy()\n",
    "    image_process_after_left[:] = 255\n",
    "    for region in con_pack:\n",
    "        for val in con_pack[region]:\n",
    "            image_process_after_left[val] = 0\n",
    "    font_object.horizontal_projection(image_process_after_left)\n",
    "    h_image_al = font_object.detect_horizontal_line(image.copy(), 0, 0)\n",
    "    start_point_h_al = font_object.start_point_h\n",
    "    coordinat_al = [0, start_point_h_al[0], w, start_point_h_al[1]]\n",
    "\n",
    "    cv2.rectangle(image_process_after_left, (coordinat_al[0], coordinat_al[1]),\n",
    "                  (coordinat_al[2], coordinat_al[3]), (0, 255, 0), 2)\n",
    "    if view:\n",
    "        cv2.imshow('d_al', image_process_after_left)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    left = [left[0], start_point_h_al[0], left[2], start_point_h_al[1]]\n",
    "    cv2.rectangle(image_process, (left[0], left[1]),\n",
    "                  (left[2], left[3]), (100, 150, 0), 2)\n",
    "\n",
    "    upper, lower = get_ul_coordinat(left, h, saved_starting_height)\n",
    "#     cv2.rectangle(image_process, (lower[0], lower[1]),\n",
    "#                           (lower[2], lower[3]), (100, 150,0), 2)\n",
    "#     cv2.rectangle(image_process, (upper[0], upper[1]),\n",
    "#                           (upper[2], upper[3]), (100, 150,0), 2)\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), upper,\n",
    "                                              left=False, right=False)\n",
    "    max_left_region = 20\n",
    "    for region in con_pack:\n",
    "        if len(con_pack[region]) > max_left_region:\n",
    "            continue\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    con_pack = font_object.eight_connectivity(image.copy(), lower,\n",
    "                                              left=False, right=False)\n",
    "    for region in con_pack:\n",
    "        if len(con_pack[region]) > max_left_region:\n",
    "            continue\n",
    "        for val in con_pack[region]:\n",
    "            image_process[val] = 0\n",
    "    if view:\n",
    "        cv2.imshow('d', image_process)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "#     con_pack = font_object.eight_connectivity(image.copy(), right,\n",
    "#                                               left=False, right=False)\n",
    "#     for region in con_pack:\n",
    "#         for val in con_pack[region]:\n",
    "#             image_process[val] = 0\n",
    "#     cv2.imshow('d', image_process)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "####\n",
    "\n",
    "    font_object.horizontal_projection(image_process)\n",
    "    al_height = start_point_h_al[1]-start_point_h_al[0]\n",
    "    print('al_height:', al_height)\n",
    "    h_image = font_object.detect_horizontal_line(image.copy(), al_height, 5)\n",
    "    start_point_h = font_object.start_point_h\n",
    "    if view:\n",
    "        cv2.imshow('line', h_image)\n",
    "        cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "    return start_point_h, image_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_blok(temp_object, imagePath, font_object, model, font_list):\n",
    "    # Get the most marker\n",
    "    count = -1\n",
    "    temp_marker_count = {}\n",
    "    for obj in temp_object:\n",
    "        count += 1\n",
    "        marker_count = 0\n",
    "        for value in obj.values():\n",
    "            if type(value) == type(np.array([])):\n",
    "                marker_count += len(value)\n",
    "        temp_marker_count[count] = marker_count\n",
    "\n",
    "    max_count = 0\n",
    "    for x in temp_marker_count:\n",
    "        if temp_marker_count[x] > max_count:\n",
    "            max_count = temp_marker_count[x]\n",
    "            max_id = x\n",
    "\n",
    "    # In[23]:\n",
    "    # Get the horizontal line image by using eight connectivity\n",
    "    img = cv2.imread(imagePath)\n",
    "    list_start_point_h = []\n",
    "    imagelist_horizontal_line_by_eight_conn = []\n",
    "    continue_flag = False\n",
    "    for key in temp_object[max_id].keys():\n",
    "        if type(temp_object[max_id][key]) == type(np.array([])):\n",
    "            split = key.split('_')\n",
    "            name = get_marker_name(key)\n",
    "            if split[1] == 'tanwin':\n",
    "                print(name)\n",
    "                for c in temp_object[max_id][key]:\n",
    "                    start_point_h, image_process = eight_conn_by_seed_tanwin(\n",
    "                        c, img, font_list, False)\n",
    "                    imagelist_horizontal_line_by_eight_conn.append(image_process)\n",
    "                    list_start_point_h.append(start_point_h)\n",
    "                    print(list_start_point_h)\n",
    "            else:\n",
    "                print(name)\n",
    "                for c in temp_object[max_id][key]:\n",
    "                    start_point_h, image_process = eight_conn_by_seed(\n",
    "                        c, img, font_list, False)\n",
    "                    imagelist_horizontal_line_by_eight_conn.append(image_process)\n",
    "                    list_start_point_h.append(start_point_h)\n",
    "                    print(list_start_point_h)\n",
    "\n",
    "    # In[24]:\n",
    "\n",
    "    img = cv2.imread(imagePath)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_copy = gray.copy()\n",
    "    height, width = gray_copy.shape\n",
    "    normal_processing = []\n",
    "    for y_y in list_start_point_h:\n",
    "        image_vo = gray[y_y[0]:y_y[1], :]\n",
    "        image_v = image_vo.copy()\n",
    "        font_object.vertical_projection(image_v)\n",
    "        font_object.detect_vertical_line(image_v.copy(), 10)\n",
    "        start_point_v = font_object.start_point_v\n",
    "        print(start_point_v)\n",
    "    #     for x in range(len(start_point_v)):\n",
    "    #         if x % 2 == 0:\n",
    "    #             cv2.line(image_v, (start_point_v[x], 0),\n",
    "    #                      (start_point_v[x], height), (0, 0, 0), 2)\n",
    "    #         else:\n",
    "    #             cv2.line(image_v, (start_point_v[x], 0),\n",
    "    #                      (start_point_v[x], height), (100, 100, 100), 2)\n",
    "    #     cv2.imshow('line', image_v)\n",
    "    #     print('>')\n",
    "    #     cv2.waitKey(0)\n",
    "\n",
    "        if len(start_point_v) > 5:\n",
    "            # Go to the normal match\n",
    "            normal_processing.append(True)\n",
    "        else:\n",
    "            # Just crop the next char by ratio\n",
    "            normal_processing.append(False)\n",
    "            print(len(start_point_v), 'is not enough')\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # In[25]:\n",
    "\n",
    "    normal_processing = most_frequent(normal_processing)\n",
    "    print(normal_processing)\n",
    "\n",
    "    # In[26]:\n",
    "\n",
    "    img = cv2.imread(imagePath)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    bw_image = cv2.adaptiveThreshold(gray, 255,\n",
    "                                     cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                     cv2.THRESH_BINARY, 11, 2)\n",
    "    height, width = gray.shape\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    temp_gray_copy = []\n",
    "    temp_image_process = []\n",
    "    temp_sub_image = []\n",
    "    temp_check_image = []\n",
    "    temp_final_img = []\n",
    "    save_state = {}\n",
    "    normal_processing_result = []\n",
    "    crop_ratio_processing_result = []\n",
    "    if normal_processing:\n",
    "        #     pass\n",
    "        save_state, imagelist_perchar_marker, imagelist_final_word_img, imagelist_final_segmented_char,\\\n",
    "         imagelist_bag_of_h_with_baseline, imagelist_image_final_body, imagelist_image_final_marker,\\\n",
    "             horizontal_image = normal_image_processing_blok(imagePath, temp_object[max_id])\n",
    "        # print('comeon', save_state)\n",
    "        # print('f', imagelist_perchar_marker)\n",
    "        # print('ddd', imagelist_final_word_img)\n",
    "        # print('normal__', imagelist_final_segmented_char)\n",
    "        normal_processing_result = [imagelist_perchar_marker,\n",
    "                                    imagelist_final_word_img,\n",
    "                                    imagelist_final_segmented_char, \n",
    "                                    imagelist_bag_of_h_with_baseline, \n",
    "                                    imagelist_image_final_body, \n",
    "                                    imagelist_image_final_marker.\n",
    "                                    horizontal_image]\n",
    "    else:\n",
    "        arr_count = -1\n",
    "        for key in temp_object[max_id].keys():\n",
    "            gray_copy = gray.copy()\n",
    "            bw = bw_image.copy()\n",
    "            if type(temp_object[max_id][key]) == type(np.array([])):\n",
    "                split = key.split('_')\n",
    "                name = get_marker_name(key)\n",
    "                if split[1] == 'tanwin':\n",
    "                    print(name)\n",
    "                    for c in temp_object[max_id][key]:\n",
    "                        y1_c = c[1]\n",
    "                        arr_count += 1\n",
    "                        oneline_coordinat = list_start_point_h[arr_count]\n",
    "                        oneline_bw_image = bw_image[oneline_coordinat[0]:\n",
    "                                                    oneline_coordinat[1], :]\n",
    "                        cv2.rectangle(gray_copy,\n",
    "                                      (0, oneline_coordinat[0]),\n",
    "                                      (width, oneline_coordinat[1]),\n",
    "                                      (0, 255, 0), 2)\n",
    "                        cv2.rectangle(gray_copy,\n",
    "                                      (c[0], c[1]),\n",
    "                                      (c[2], c[3]),\n",
    "                                      (0, 255, 0), 2)\n",
    "                        # cv2.imshow('check', gray_copy)\n",
    "                        # cv2.waitKey(0)\n",
    "                        c = region_tanwin(c, bw_image, font_list, False)\n",
    "                        next_c, _ = get_lr_coordinat(c, width)\n",
    "                        next_c_count = black_pixel_count(bw_image, next_c)\n",
    "                        while(next_c_count < 2):\n",
    "                            next_c, _ = get_lr_coordinat(next_c, width)\n",
    "                            next_c_count = black_pixel_count(bw_image, next_c)\n",
    "                            if next_c[0] < 1:\n",
    "                                break\n",
    "                        if next_c[1] > y1_c:\n",
    "                            mod_c, _ = get_ul_coordinat(next_c, height)\n",
    "                            next_c = [next_c[0], mod_c[1],\n",
    "                                      next_c[2], next_c[3]]\n",
    "                        else:\n",
    "                            _, mod_c = get_ul_coordinat(next_c, height)\n",
    "                            next_c = [next_c[0], next_c[1],\n",
    "                                      next_c[2], mod_c[3]]\n",
    "                        cv2.rectangle(gray_copy,\n",
    "                                      (next_c[0], next_c[1]),\n",
    "                                      (next_c[2], next_c[3]),\n",
    "                                      (200, 150, 0), 2)\n",
    "                        temp_height = c[3] - c[1]\n",
    "                        crop_by = int(1/4 * temp_height)\n",
    "                        crop_image = bw[next_c[1]+crop_by:next_c[3]  # -crop_by\n",
    "                                        , next_c[0]:next_c[2]]\n",
    "                        one_base = raw_baseline(crop_image.copy(), font_object)\n",
    "                        cv2.rectangle(gray_copy,\n",
    "                                      (0, c[1] + one_base[0]),\n",
    "                                      (width, c[1] + one_base[1]),\n",
    "                                      (1000, 150, 0), 2)\n",
    "    #                     crop_image = cv2.morphologyEx(crop_image,\n",
    "    #                                                   cv2.MORPH_OPEN, kernel)\n",
    "    #                     crop_image = cv2.erode(crop_image,kernel,iterations = 1)\n",
    "                        # cv2.imshow('ff', crop_image)\n",
    "                        # cv2.waitKey(0)\n",
    "                        h_crop, w_crop = crop_image.shape\n",
    "                        base = [0, one_base[0],\n",
    "                                w_crop-1, one_base[1]]\n",
    "                        con_pack = font_object.eight_connectivity(crop_image, base,\n",
    "                                                                  left=False, right=False)\n",
    "                        image_process = crop_image.copy()\n",
    "                        image_process[:] = 255\n",
    "                        for region in con_pack:\n",
    "                            for val in con_pack[region]:\n",
    "                                image_process[val] = 0\n",
    "                        # cv2.imshow('d', image_process)\n",
    "                        # cv2.waitKey(0)\n",
    "                        sub_image = cv2.subtract(image_process, crop_image)\n",
    "                        sub_image = cv2.bitwise_not(sub_image)\n",
    "    #                     final_c = [int(1/2*w_next), 0, w_crop, h_crop]\n",
    "                        final_c = [0, 0, w_crop, h_crop]\n",
    "                        check_img = sub_image[final_c[1]:final_c[3],\n",
    "                                              final_c[0]:final_c[2]]\n",
    "                        final_img = image_process[final_c[1]:final_c[3],\n",
    "                                                  final_c[0]:final_c[2]]\n",
    "                        dot = font_object.dot_checker(check_img)\n",
    "                        if dot:\n",
    "                            final_img = cv2.bitwise_and(check_img, final_img)\n",
    "#                             final_img = cv2.add(check_img, final_img)\n",
    "                        # cv2.imshow('final', final_img)\n",
    "                        # cv2.waitKey(0)\n",
    "\n",
    "                        save_state[arr_count] = []\n",
    "                        save_state[arr_count].append(name)\n",
    "                        save_state[arr_count].append(1)  # scale\n",
    "                        save_state[arr_count].append(0)  # y_origin\n",
    "                        save_state[arr_count].append(c)  # marker_coordinat\n",
    "                        save_state[arr_count].append(final_img)\n",
    "                        save_state[arr_count].append(next_c[0])\n",
    "\n",
    "                        temp_gray_copy.append(gray_copy)\n",
    "                        temp_image_process.append(image_process)\n",
    "                        temp_sub_image.append(sub_image)\n",
    "                        temp_check_image.append(check_img)\n",
    "                        temp_final_img.append(final_img)\n",
    "\n",
    "    #                     raw_baseline(oneline_coordinat, bw_image)\n",
    "    #                     temp_height = c[3] - c[1]\n",
    "    #                     crop_by = int(1/4 * temp_height)\n",
    "    #                     crop_image = bw_image[c[1]+crop_by:c[3]#-crop_by\n",
    "    #                                           , c[0]:c[2]]\n",
    "    #                     one_base = raw_baseline(crop_image)\n",
    "    #                     cv2.rectangle(gray_copy,\n",
    "    #                                   (0, c[1] + one_base[0]),\n",
    "    #                                   (width, c[1] + one_base[1]),\n",
    "    #                                   (1000, 150,0), 2)\n",
    "\n",
    "    #                     base = [0, one_base[0],\n",
    "    #                             width, one_base[1]]\n",
    "    #                     con_pack = font_object.eight_connectivity(oneline_bw_image, base,\n",
    "    #                                               left=False, right=False)\n",
    "    #                     image_process = oneline_bw_image.copy()\n",
    "    #                     image_process[:] = 255\n",
    "    #                     for region in con_pack:\n",
    "    #                         for val in con_pack[region]:\n",
    "    #                             image_process[val] = 0\n",
    "    #                     cv2.imshow('d', image_process)\n",
    "    #                     cv2.waitKey(0)\n",
    "\n",
    "    #                     font_object.modified_eight_connectivity(oneline_bw_image, one_base)\n",
    "    #                     font_object.grouping_marker()\n",
    "\n",
    "    #                     cv2.imshow('image final marker', font_object.image_final_marker)\n",
    "    #                     cv2.imshow('image final body', font_object.image_final_sorted)\n",
    "    #                     cv2.waitKey(0)\n",
    "                else:\n",
    "                    print(name)\n",
    "                    for c in temp_object[max_id][key]:\n",
    "                        arr_count += 1\n",
    "                        oneline_coordinat = list_start_point_h[arr_count]\n",
    "                        oneline_bw_image = bw_image[oneline_coordinat[0]:\n",
    "                                                    oneline_coordinat[1], :]\n",
    "                        cv2.rectangle(gray_copy,\n",
    "                                      (0, oneline_coordinat[0]),\n",
    "                                      (width, oneline_coordinat[1]),\n",
    "                                      (0, 255, 0), 2)\n",
    "                        cv2.rectangle(gray_copy,\n",
    "                                      (c[0], c[1]),\n",
    "                                      (c[2], c[3]),\n",
    "                                      (0, 255, 0), 2)\n",
    "                        # cv2.imshow('check', gray_copy)\n",
    "                        # cv2.waitKey(0)\n",
    "                        next_c, _ = get_lr_coordinat(c, width)\n",
    "                        next_c_count = black_pixel_count(bw_image, next_c)\n",
    "                        while(next_c_count < 2):\n",
    "                            next_c, _ = get_lr_coordinat(next_c, width)\n",
    "                            next_c_count = black_pixel_count(bw_image, next_c)\n",
    "                            if next_c[0] < 1:\n",
    "                                break\n",
    "                        mod_c, _ = get_lr_coordinat(next_c, width)\n",
    "                        w_next = mod_c[2] - mod_c[0]\n",
    "                        next_c = [next_c[0] - int(1/2*w_next), next_c[1],\n",
    "                                  next_c[2], next_c[3]]\n",
    "                        cv2.rectangle(gray_copy,\n",
    "                                      (next_c[0], next_c[1]),\n",
    "                                      (next_c[2], next_c[3]),\n",
    "                                      (200, 150, 0), 2)\n",
    "                        temp_height = c[3] - c[1]\n",
    "                        crop_by = int(1/4 * temp_height)\n",
    "                        crop_image = bw[next_c[1]+crop_by:next_c[3]  # -crop_by\n",
    "                                        , next_c[0]:next_c[2]]\n",
    "                        one_base = raw_baseline(crop_image.copy(), font_object)\n",
    "                        cv2.rectangle(gray_copy,\n",
    "                                      (0, c[1] + one_base[0]),\n",
    "                                      (width, c[1] + one_base[1]),\n",
    "                                      (1000, 150, 0), 2)\n",
    "    #                     crop_image = cv2.morphologyEx(crop_image,\n",
    "    #                                                   cv2.MORPH_OPEN, kernel)\n",
    "    #                     crop_image = cv2.erode(crop_image,kernel,iterations = 1)\n",
    "                        # cv2.imshow('ff', crop_image)\n",
    "                        # cv2.waitKey(0)\n",
    "                        h_crop, w_crop = crop_image.shape\n",
    "                        base = [0, one_base[0],\n",
    "                                w_crop-1, one_base[1]]\n",
    "                        con_pack = font_object.eight_connectivity(crop_image, base,\n",
    "                                                                  left=False, right=False)\n",
    "                        image_process = crop_image.copy()\n",
    "                        image_process[:] = 255\n",
    "                        for region in con_pack:\n",
    "                            for val in con_pack[region]:\n",
    "                                image_process[val] = 0\n",
    "                        # cv2.imshow('d', image_process)\n",
    "                        # cv2.waitKey(0)\n",
    "                        sub_image = cv2.subtract(image_process, crop_image)\n",
    "                        sub_image = cv2.bitwise_not(sub_image)\n",
    "                        final_c = [int(1/2*w_next), 0, w_crop, h_crop]\n",
    "                        check_img = sub_image[final_c[1]:final_c[3],\n",
    "                                              final_c[0]:final_c[2]]\n",
    "                        final_img = image_process[final_c[1]:final_c[3],\n",
    "                                                  final_c[0]:final_c[2]]\n",
    "                        dot = font_object.dot_checker(check_img)\n",
    "                        if dot:\n",
    "                            print('dot')\n",
    "                            final_img = cv2.bitwise_and(check_img, final_img)\n",
    "#                             final_img = cv2.add(final_img, check_img)\n",
    "                        # cv2.imshow('final', final_img)\n",
    "                        # cv2.waitKey(0)\n",
    "\n",
    "                        save_state[arr_count] = []\n",
    "                        save_state[arr_count].append(name)\n",
    "                        save_state[arr_count].append(1)  # scale\n",
    "                        save_state[arr_count].append(0)  # y_origin\n",
    "                        save_state[arr_count].append(c)  # marker_coordinat\n",
    "                        save_state[arr_count].append(final_img)\n",
    "                        save_state[arr_count].append(\n",
    "                            next_c[0] + int(1/2*w_next))\n",
    "                \n",
    "                        temp_gray_copy.append(gray_copy)\n",
    "                        temp_image_process.append(image_process)\n",
    "                        temp_sub_image.append(sub_image)\n",
    "                        temp_check_image.append(check_img)\n",
    "                        temp_final_img.append(final_img)\n",
    "\n",
    "        crop_ratio_processing_result = [temp_gray_copy,\n",
    "                                        temp_image_process,\n",
    "                                        temp_sub_image,\n",
    "                                        temp_check_image,\n",
    "                                        temp_final_img]\n",
    "    \n",
    "    return crop_ratio_processing_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanwin_1\n",
      "start point from mess: [506, 538]\n",
      "[393, 487, 411, 505]\n",
      "[393, 523, 411, 541]\n",
      "upper\n",
      "319\n",
      "start point from mess: [477, 504]\n",
      "al_height: 27\n",
      "start point from mess: [437, 538]\n",
      "[[437, 538]]\n",
      "start point from mess: [280, 314]\n",
      "[319, 260, 337, 278]\n",
      "[319, 296, 337, 314]\n",
      "upper\n",
      "123\n",
      "384\n",
      "start point from mess: [237, 281]\n",
      "al_height: 44\n",
      "start point from mess: [226, 314]\n",
      "[[437, 538], [226, 314]]\n",
      "nun_stand\n",
      "start point from mess: [376, 432]\n",
      "leftcount: 326\n",
      "start point from mess: [376, 440]\n",
      "al_height: 64\n",
      "start point from mess: [350, 475]\n",
      "[[437, 538], [226, 314], [350, 475]]\n",
      "start point from mess: [245, 277]\n",
      "leftcount: 324\n",
      "start point from mess: [213, 278]\n",
      "al_height: 65\n",
      "start point from mess: [179, 310]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310]]\n",
      "mim_beg\n",
      "start point from mess: [321, 352]\n",
      "leftcount: 129\n",
      "start point from mess: [324, 352]\n",
      "al_height: 28\n",
      "start point from mess: [313, 379]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379]]\n",
      "start point from mess: [148, 192]\n",
      "leftcount: 116\n",
      "start point from mess: [148, 192]\n",
      "al_height: 44\n",
      "start point from mess: [141, 218]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218]]\n",
      "mim_mid\n",
      "start point from mess: [336, 359]\n",
      "leftcount: 91\n",
      "start point from mess: [330, 360]\n",
      "al_height: 30\n",
      "start point from mess: [316, 363]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218], [316, 363]]\n",
      "start point from mess: [288, 320]\n",
      "leftcount: 46\n",
      "start point from mess: [288, 322]\n",
      "al_height: 34\n",
      "start point from mess: [272, 330]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218], [316, 363], [272, 330]]\n",
      "mim_end\n",
      "start point from mess: [589, 617]\n",
      "leftcount: 168\n",
      "start point from mess: [589, 617]\n",
      "al_height: 28\n",
      "start point from mess: [571, 632]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218], [316, 363], [272, 330], [571, 632]]\n",
      "start point from mess: [243, 277]\n",
      "leftcount: 104\n",
      "start point from mess: [245, 277]\n",
      "al_height: 32\n",
      "start point from mess: [243, 301]\n",
      "[[437, 538], [226, 314], [350, 475], [179, 310], [313, 379], [141, 218], [316, 363], [272, 330], [571, 632], [243, 301]]\n",
      "[39, 499]\n",
      "2 is not enough\n",
      "[19, 487, 490, 499]\n",
      "4 is not enough\n",
      "[24, 499]\n",
      "2 is not enough\n",
      "[19, 487, 490, 499]\n",
      "4 is not enough\n",
      "[32, 486, 488, 499]\n",
      "4 is not enough\n",
      "[18, 487, 491, 499]\n",
      "4 is not enough\n",
      "[32, 102, 104, 486, 489, 499]\n",
      "[32, 188, 190, 486, 490, 499]\n",
      "[48, 499]\n",
      "2 is not enough\n",
      "[19, 201, 203, 448, 452, 479, 490, 499]\n",
      "False\n",
      "tanwin_1\n",
      "start point from mess: [506, 538]\n",
      "[393, 487, 411, 505]\n",
      "[393, 523, 411, 541]\n",
      "start point from mess: [0, 31]\n",
      "start point from mess: [280, 314]\n",
      "[319, 260, 337, 278]\n",
      "[319, 296, 337, 314]\n",
      "start point from mess: [0, 31]\n",
      "nun_stand\n",
      "start point from mess: [0, 27]\n",
      "start point from mess: [0, 27]\n",
      "dot\n",
      "mim_beg\n",
      "start point from mess: [0, 20]\n",
      "start point from mess: [1, 20]\n",
      "mim_mid\n",
      "start point from mess: [0, 15]\n",
      "start point from mess: [0, 15]\n",
      "mim_end\n",
      "start point from mess: [0, 18]\n",
      "start point from mess: [0, 12]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "crop_ratio_processing_result = big_blok(temp_object, imagePath, font_object, model, font_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in crop_ratio_processing_result[0]:\n",
    "    cv2.imshow('final_img', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_ratio_processing_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
